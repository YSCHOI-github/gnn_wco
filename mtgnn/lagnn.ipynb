{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "finnish-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import List, NamedTuple, Optional\n",
    "import scipy.sparse as sp\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, LightningDataModule\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../graph_sage')\n",
    "import parser\n",
    "import dataset\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from custom_parser import get_parser\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import from_networkx, to_undirected\n",
    "from torch_geometric.data import Data, DataLoader, Dataset, NeighborSampler\n",
    "from torch_geometric.nn import SAGEConv, MessagePassing\n",
    "\n",
    "from torch_cluster import random_walk\n",
    "\n",
    "from torch import Tensor\n",
    "# from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "%config Completer.use_jedi = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "waiting-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.Tdata(path='../../tdata.csv')\n",
    "parser = get_parser()\n",
    "args = parser.parse_args(args=\n",
    "                         [\"--data\",\"real-t\", \n",
    "                          \"--sampling\",\"xgb\",\n",
    "                          \"--mode\",\"scratch\",\n",
    "                          \"--train_from\",\"20170101\",\n",
    "                          \"--test_from\",\"20190101\",\n",
    "                          \"--test_length\",\"365\",\n",
    "                          \"--valid_length\",\"90\",\n",
    "                          \"--initial_inspection_rate\", \"5\",\n",
    "                          \"--final_inspection_rate\", \"10\",\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "invisible-monthly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:\n",
      "Train labeled: (77391, 41), Train unlabeled: (1470434, 41), Valid labeled: (134457, 41), Valid unlabeled: (0, 13), Test: (703090, 41)\n",
      "Checking label distribution\n",
      "Training: 0.09757342825942052\n",
      "Validation: 0.09589052260946108\n",
      "Testing: 0.10476480792437651\n"
     ]
    }
   ],
   "source": [
    "# args\n",
    "seed = args.seed\n",
    "epochs = args.epoch\n",
    "dim = args.dim\n",
    "lr = args.lr\n",
    "weight_decay = args.l2\n",
    "initial_inspection_rate = args.initial_inspection_rate\n",
    "inspection_rate_option = args.inspection_plan\n",
    "mode = args.mode\n",
    "train_begin = args.train_from \n",
    "test_begin = args.test_from\n",
    "test_length = args.test_length\n",
    "valid_length = args.valid_length\n",
    "chosen_data = args.data\n",
    "numWeeks = args.numweeks\n",
    "semi_supervised = args.semi_supervised\n",
    "save = args.save\n",
    "gpu_id = args.device\n",
    "\n",
    "# Initial dataset split\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Initial dataset split\n",
    "train_start_day = datetime.date(int(train_begin[:4]), int(train_begin[4:6]), int(train_begin[6:8]))\n",
    "test_start_day = datetime.date(int(test_begin[:4]), int(test_begin[4:6]), int(test_begin[6:8]))\n",
    "test_length = timedelta(days=test_length)    \n",
    "test_end_day = test_start_day + test_length\n",
    "valid_length = timedelta(days=valid_length)\n",
    "valid_start_day = test_start_day - valid_length\n",
    "\n",
    "# data\n",
    "data.split(train_start_day, valid_start_day, test_start_day, test_end_day, valid_length, test_length, args)\n",
    "data.featureEngineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pressing-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../graph_sage')\n",
    "from utils import *\n",
    "from pygData_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dimensional-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n"
     ]
    }
   ],
   "source": [
    "categories=[\"importer.id\",\"HS6\"]\n",
    "gdata = GraphData(data,use_xgb=True, categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stuffed-recorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking top 1% suspicious transactions: 1345\n",
      "Precision: 0.6349, Recall: 0.0726, Revenue: 0.0725\n",
      "Checking top 2% suspicious transactions: 2690\n",
      "Precision: 0.5520, Recall: 0.1262, Revenue: 0.1187\n",
      "Checking top 5% suspicious transactions: 6723\n",
      "Precision: 0.4261, Recall: 0.2435, Revenue: 0.2367\n",
      "Checking top 10% suspicious transactions: 13446\n",
      "Precision: 0.3139, Recall: 0.3588, Revenue: 0.3490\n",
      "--------------------------------------------------\n",
      "Checking top 1% suspicious transactions: 7031\n",
      "Precision: 0.7042, Recall: 0.0743, Revenue: 0.1217\n",
      "Checking top 2% suspicious transactions: 14062\n",
      "Precision: 0.6039, Recall: 0.1274, Revenue: 0.2024\n",
      "Checking top 5% suspicious transactions: 35155\n",
      "Precision: 0.4473, Recall: 0.2359, Revenue: 0.3511\n",
      "Checking top 10% suspicious transactions: 70309\n",
      "Precision: 0.3258, Recall: 0.3436, Revenue: 0.4705\n"
     ]
    }
   ],
   "source": [
    "best_thresh, best_auc = find_best_threshold(gdata.xgb,data.dfvalidx_lab, data.valid_cls_label)\n",
    "xgb_test_pred = gdata.xgb.predict_proba(data.dfvalidx_lab)[:,-1]\n",
    "overall_f1,auc,pr, re, f, rev = metrics(xgb_test_pred, data.valid_cls_label,data.valid_reg_label,best_thresh)\n",
    "print(\"-\"*50)\n",
    "xgb_test_pred = gdata.xgb.predict_proba(data.dftestx)[:,-1]\n",
    "overall_f1,auc,pr, re, f, rev = metrics(xgb_test_pred, data.test_cls_label,data.test_reg_label,best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "racial-asbestos",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[154782], edge_index=[2, 309564], edge_label=[309564], node_idx=[77391], rev=[92606], x=[92606, 100], y=[92606])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage = \"train_lab\"\n",
    "trainLab_data = gdata.get_data(stage)\n",
    "train_nodeidx = torch.tensor(gdata.get_AttNode(stage))\n",
    "trainLab_data.node_idx = train_nodeidx\n",
    "trainLab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "stuck-church",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[2940868], edge_index=[2, 5881736], edge_label=[5881736], node_idx=[1470434], rev=[1515745], x=[1515745, 100], y=[1515745])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage = \"train_unlab\"\n",
    "unlab_data = gdata.get_data(stage)\n",
    "unlab_nodeidx = torch.tensor(gdata.get_AttNode(stage))\n",
    "unlab_data.node_idx = unlab_nodeidx\n",
    "unlab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "absent-immunology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[268914], edge_index=[2, 537828], edge_label=[537828], node_idx=[134457], rev=[137035], x=[137035, 100], y=[137035])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage = \"valid\"\n",
    "valid_data = gdata.get_data(stage)\n",
    "valid_nodeidx = torch.tensor(gdata.get_AttNode(stage))\n",
    "valid_data.node_idx = valid_nodeidx\n",
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wireless-compression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[1406180], edge_index=[2, 2812360], edge_label=[2812360], node_idx=[703090], rev=[718094], x=[718094, 100], y=[718094])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage = \"test\"\n",
    "test_data = gdata.get_data(stage)\n",
    "test_nodeidx = torch.tensor(gdata.get_AttNode(stage))\n",
    "test_data.node_idx = test_nodeidx\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "narrative-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainLab_data, 'train_lab_data.pt')\n",
    "torch.save(unlab_data, 'train_unlab_data.pt')\n",
    "torch.save(valid_data, 'valid_data.pt')\n",
    "torch.save(test_data, 'test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "integral-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainLab_data, gdata.leaf_dim\n",
    "# gdata.leaf_dim # 1562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "acute-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(trainLab_data, 'train_data.pt')\n",
    "from data import StackData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "voluntary-pledge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lab_data = torch.load('train_lab_data.pt')\n",
    "train_lab_data\n",
    "\n",
    "train_unlab_data = torch.load('train_unlab_data.pt')\n",
    "train_unlab_data\n",
    "\n",
    "valid_data = torch.load('valid_data.pt')\n",
    "valid_data\n",
    "\n",
    "test_data = torch.load('test_data.pt')\n",
    "test_data.y[test_data.node_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "simplified-saver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[1716360], edge_index=[2, 3432720], edge_label=[3432720], node_idx=[858180], rev=[901165], x=[901165, 100], y=[901165])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-horizon",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "amateur-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch(NamedTuple):\n",
    "    '''\n",
    "    convert batch data for pytorch-lightning\n",
    "    '''\n",
    "    x: Tensor\n",
    "    y: Tensor\n",
    "    rev: Tensor\n",
    "    adjs_t: NamedTuple\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        return Batch(\n",
    "            x=self.x.to(*args, **kwargs),\n",
    "            y=self.y.to(*args, **kwargs),\n",
    "            rev=self.rev.to(*args, **kwargs),\n",
    "            adjs_t=[(adj_t.to(*args, **kwargs), eid.to(*args, **kwargs), size) for adj_t, eid, size in self.adjs_t],\n",
    "        )\n",
    "    \n",
    "class UnsupNeighborSampler(NeighborSampler):\n",
    "    \n",
    "    def sample(self, batch):\n",
    "        batch = torch.tensor(batch)\n",
    "        row, col, _ = self.adj_t.coo()\n",
    "\n",
    "        # For each node in `batch`, we sample a direct neighbor (as positive\n",
    "        # example) and a random node (as negative example):\n",
    "        pos_batch = random_walk(row, col, batch, walk_length=1,\n",
    "                                coalesced=False)[:, 1]\n",
    "\n",
    "        neg_batch = torch.randint(0, self.adj_t.size(1), (batch.numel(), ),\n",
    "                                  dtype=torch.long)\n",
    "\n",
    "        batch = torch.cat([batch, pos_batch, neg_batch], dim=0)\n",
    "        return super(UnsupNeighborSampler, self).sample(batch)\n",
    "    \n",
    "class CustomData(LightningDataModule):\n",
    "    def __init__(self,train_data, valid_data, sizes, batch_size):\n",
    "        super(CustomData,self).__init__()\n",
    "\n",
    "        self.train_data = train_data\n",
    "        self.valid_data = valid_data\n",
    "        \n",
    "        self.sizes = sizes\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return UnsupNeighborSampler(self.train_data.edge_index, node_idx=self.train_data.node_idx,\n",
    "                               sizes=self.sizes, return_e_id=True,\n",
    "                               batch_size=self.batch_size,\n",
    "                               shuffle=True,\n",
    "                               drop_last=True,\n",
    "                               transform=self.convert_train_batch,\n",
    "                               num_workers=16)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return NeighborSampler(self.valid_data.edge_index, \n",
    "                               node_idx=self.valid_data.node_idx,\n",
    "                               sizes=self.sizes, \n",
    "                               return_e_id=True,\n",
    "                               batch_size=self.batch_size,\n",
    "                               shuffle=False,\n",
    "                               drop_last=True,\n",
    "                               transform=self.convert_valid_batch\n",
    "                              )\n",
    "\n",
    "    def convert_train_batch(self, batch_size, n_id, adjs):\n",
    "        return Batch(\n",
    "            x=self.train_data.x[n_id],\n",
    "            y=self.train_data.y[n_id[:batch_size]],\n",
    "            rev = self.train_data.rev[n_id[:batch_size]],\n",
    "            adjs_t=adjs,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def convert_valid_batch(self, batch_size, n_id, adjs):\n",
    "        return Batch(\n",
    "            x=self.valid_data.x[n_id],\n",
    "            y=self.valid_data.y[n_id[:batch_size]],\n",
    "            rev = self.valid_data.rev[n_id[:batch_size]],\n",
    "            adjs_t=adjs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-phone",
   "metadata": {},
   "source": [
    "# Unsupervised Graph Sage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "skilled-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers, leaf_len):\n",
    "        super(SAGE, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "        self.emb = nn.Embedding(leaf_len, in_channels, padding_idx=0)\n",
    "#         self.bn = nn.BatchNorm1d(in_channels)\n",
    "        self.ln = nn.LayerNorm(in_channels)\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            in_channels = in_channels if i == 0 else hidden_channels\n",
    "            self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "\n",
    "        \n",
    "    def forward(self, x, adjs):\n",
    "        \n",
    "        x = self.emb(x)\n",
    "\n",
    "        x = torch.sum(x,dim=1) # summation over the leaves\n",
    "#         x = F.relu(self.bn(x))\n",
    "        x = F.relu(self.ln(x))\n",
    "        \n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
    "            x = self.convs[i]((x, x_target), edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "                \n",
    "        return x\n",
    "\n",
    "#     def full_forward(self, x, edge_index):\n",
    "        \n",
    "#         x = self.emb(x)\n",
    "\n",
    "#         x = torch.sum(x,dim=1) # summation over the leaves\n",
    "#         x = F.relu(self.bn(x))\n",
    "        \n",
    "#         for i, conv in enumerate(self.convs):\n",
    "#             x = conv(x, edge_index)\n",
    "#             if i != self.num_layers - 1:\n",
    "#                 x = x.relu()\n",
    "#                 x = F.dropout(x, p=0.5, training=self.training)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "wireless-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SAGE\n",
    "\n",
    "class SageModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(SageModel, self).__init__()\n",
    "        \n",
    "        self.sage = SAGE( \n",
    "            in_channels=128, \n",
    "            hidden_channels=128, \n",
    "            num_layers=2, \n",
    "            leaf_len=1562)\n",
    "        \n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, adjs):\n",
    "        \n",
    "        return self.sage(x, adjs)\n",
    "        \n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, rev, adjs = batch\n",
    "        \n",
    "        out = self.forward(x, adjs)\n",
    "        \n",
    "        out, pos_out, neg_out = out.split(out.size(0) // 3, dim=0)\n",
    "        out_y = y[:out.size(0)]\n",
    "\n",
    "        pos_loss = F.logsigmoid((out * pos_out).sum(-1)).mean()\n",
    "        neg_loss = F.logsigmoid(-(out * neg_out).sum(-1)).mean()\n",
    "        loss = -pos_loss - neg_loss\n",
    "        \n",
    "#         print(out.shape, y.shape)\n",
    "        if not self.X is None:\n",
    "            self.X = torch.cat([self.X, out.detach().cpu()])\n",
    "            self.y = torch.cat([self.y, out_y.flatten().detach().cpu()])\n",
    "        else:\n",
    "            self.X = out.detach().cpu()\n",
    "            self.y = out_y.flatten().detach().cpu()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, rev, adjs = batch\n",
    "        \n",
    "        features = self.forward(x, adjs)\n",
    "                \n",
    "        return {'features':features, 'y': y.flatten()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \n",
    "        valid_X = torch.cat([x[\"features\"] for x in outputs], dim=0).detach().cpu()\n",
    "        y_true = torch.cat([x[\"y\"] for x in outputs], dim=0).detach().cpu()\n",
    "        \n",
    "        clf = LogisticRegression(max_iter=1e3)\n",
    "        clf.fit(self.X, self.y)\n",
    "        \n",
    "        y_pred = clf.predict(valid_X)\n",
    "        \n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        \n",
    "        self.log('f1', f1, prog_bar=True)\n",
    "        \n",
    "        self.X = None\n",
    "        self.y = None\n",
    "            \n",
    "    def optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None, on_tpu=False, using_native_amp=True, using_lbfgs=False):\n",
    "                \n",
    "        optimizer.step(closure=second_order_closure)\n",
    "\n",
    "        self.scheduler.step(current_epoch + batch_nb / len(data_loader.train_dataloader()))\n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "        \n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=epochs, T_mult=1, eta_min=0, last_epoch=-1, verbose=True)\n",
    "                \n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "successful-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SageModel.load_from_checkpoint(checkpoint_path='unsup_checkpoints/epoch=01-f1=0.6181.ckpt')\n",
    "torch.save(m.sage.state_dict(), 'large_neighb_unsup_sage.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-graphic",
   "metadata": {},
   "source": [
    "# Unsupervised training of Graph Sage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "occupied-invitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using environment variable NODE_RANK for node rank (0).\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | sage | SAGE | 223 K \n",
      "------------------------------\n",
      "223 K     Trainable params\n",
      "0         Non-trainable params\n",
      "223 K     Total params\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_len = 1549\n",
    "\n",
    "batch_size = 256\n",
    "sizes = [-1, 200]\n",
    "epochs=100\n",
    "\n",
    "data_loader = CustomData(train_lab_data, valid_lab_data, sizes, batch_size)\n",
    "\n",
    "model = SageModel( \n",
    "    in_channels=128, \n",
    "    hidden_channels=64, \n",
    "    num_layers=2, \n",
    "    leaf_len=leaf_len)\n",
    "\n",
    "trainer = Trainer(\n",
    "    gpus=[0],\n",
    "    progress_bar_refresh_rate=0,\n",
    "    num_sanity_val_steps=0,\n",
    "    max_epochs=epochs)\n",
    "trainer.fit(model, data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-ethics",
   "metadata": {},
   "source": [
    "# Supervised data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "molecular-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupData(LightningDataModule):\n",
    "    def __init__(self,train_data, valid_data, sizes, batch_size):\n",
    "        super(SupData,self).__init__()\n",
    "\n",
    "        self.train_data = train_data\n",
    "        self.valid_data = valid_data\n",
    "        \n",
    "        self.sizes = sizes\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return NeighborSampler(self.train_data.edge_index, node_idx=self.train_data.node_idx,\n",
    "                               sizes=self.sizes, return_e_id=True,\n",
    "                               batch_size=self.batch_size,\n",
    "                               shuffle=True,\n",
    "                               drop_last=True,\n",
    "                               transform=self.convert_train_batch,\n",
    "                               num_workers=16)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return NeighborSampler(self.valid_data.edge_index, \n",
    "                               node_idx=self.valid_data.node_idx,\n",
    "                               sizes=self.sizes, \n",
    "                               return_e_id=True,\n",
    "                               batch_size=self.batch_size,\n",
    "                               shuffle=False,\n",
    "                               drop_last=True,\n",
    "                               transform=self.convert_valid_batch\n",
    "                              )\n",
    "\n",
    "    def convert_train_batch(self, batch_size, n_id, adjs):\n",
    "        return Batch(\n",
    "            x=self.train_data.x[n_id],\n",
    "            y=self.train_data.y[n_id[:batch_size]],\n",
    "            rev = self.train_data.rev[n_id[:batch_size]],\n",
    "            adjs_t=adjs,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def convert_valid_batch(self, batch_size, n_id, adjs):\n",
    "        return Batch(\n",
    "            x=self.valid_data.x[n_id],\n",
    "            y=self.valid_data.y[n_id[:batch_size]],\n",
    "            rev = self.valid_data.rev[n_id[:batch_size]],\n",
    "            adjs_t=adjs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-constitutional",
   "metadata": {},
   "source": [
    "# LaGNN + GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "broken-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, **kwargs):\n",
    "        super(LabelPredictor, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(in_channels * 3, 1)\n",
    "        \n",
    "    def forward(self, x): \n",
    "      \n",
    "        emb_a = x\n",
    "        emb_b = x.roll(1,0)\n",
    "        \n",
    "        emb_abs = torch.abs(emb_a - emb_b)\n",
    "        emb_sum = emb_a + emb_b\n",
    "        emb_mult = emb_a * emb_b\n",
    "        \n",
    "        x = torch.cat([emb_abs, emb_sum, emb_mult], dim=-1)\n",
    "\n",
    "        x = self.linear(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def edge_forward(self, emb_a, emb_b):\n",
    "                \n",
    "        emb_abs = torch.abs(emb_a - emb_b)\n",
    "        emb_sum = emb_a + emb_b\n",
    "        emb_mult = emb_a * emb_b\n",
    "        \n",
    "        x = torch.cat([emb_abs, emb_sum, emb_mult], dim=-1)\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ambient-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class LabelPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super(LabelPredictor, self).__init__()\n",
    "        \n",
    "        self.lin1 = nn.Linear(in_channels * 3, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, 1)\n",
    "        \n",
    "        self.ln = nn.LayerNorm(hidden_channels)\n",
    "\n",
    "#         self.linear = nn.Linear(in_channels * 3, 1)\n",
    "        \n",
    "    def forward(self, x): \n",
    "      \n",
    "        emb_a = x\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        index = torch.randperm(batch_size)\n",
    "        \n",
    "        emb_b = x[index]\n",
    "        \n",
    "        emb_a = emb_a.detach()\n",
    "        emb_b = emb_b.detach()\n",
    "        \n",
    "        emb_abs = torch.abs(emb_a - emb_b)\n",
    "        emb_sum = emb_a + emb_b\n",
    "        emb_mult = emb_a * emb_b\n",
    "        \n",
    "        x = torch.cat([emb_abs, emb_sum, emb_mult], dim=-1)\n",
    "\n",
    "        x = F.relu(self.ln(self.lin1(x)))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = torch.sigmoid(self.lin2(x))\n",
    "\n",
    "\n",
    "#         x = self.linear(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "        \n",
    "        return x, index\n",
    "    \n",
    "    def edge_forward(self, emb_a, emb_b):\n",
    "                \n",
    "        emb_abs = torch.abs(emb_a - emb_b)\n",
    "        emb_sum = emb_a + emb_b\n",
    "        emb_mult = emb_a * emb_b\n",
    "        \n",
    "        x = torch.cat([emb_abs, emb_sum, emb_mult], dim=-1)\n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = torch.sigmoid(self.lin2(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class LabelModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(LabelModel, self).__init__()\n",
    "        \n",
    "        self.unsup_sage = SAGE( \n",
    "            in_channels=128, \n",
    "            hidden_channels=128, \n",
    "            num_layers=2, \n",
    "            leaf_len=1562)\n",
    "        self.unsup_sage.load_state_dict(torch.load('large_neighb_unsup_sage.pt'))\n",
    "        \n",
    "        for p in self.unsup_sage.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        \n",
    "        self.label_predictor = LabelPredictor(in_channels=128, hidden_channels=128)\n",
    "        \n",
    "    def forward(self, x, adjs):\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "        x = self.unsup_sage(x, adjs)        \n",
    "        return self.label_predictor(x)\n",
    "                \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, rev, adjs = batch\n",
    "        \n",
    "        y_pred, index = self.forward(x, adjs)\n",
    "\n",
    "        y_true = (y == y[index]).float()\n",
    "\n",
    "        loss = F.binary_cross_entropy(y_pred.flatten(), y_true.flatten())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, rev, adjs = batch\n",
    "        \n",
    "        threshold = 0.5\n",
    "        \n",
    "        y_pred, index = self.forward(x, adjs)\n",
    "\n",
    "        y_true = (y == y[index]).float()\n",
    "\n",
    "        val_loss = F.binary_cross_entropy(y_pred.flatten(), y_true.flatten())\n",
    "        \n",
    "        y_pred[y_pred >= threshold] = 1\n",
    "        y_pred[y_pred < threshold] = 0\n",
    "                \n",
    "        return {'y_pred':y_pred.flatten(), 'y_true': y_true.flatten(), 'val_loss': val_loss.item()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \n",
    "        val_loss = np.mean([x[\"val_loss\"] for x in outputs])\n",
    "        y_pred = torch.cat([x[\"y_pred\"] for x in outputs], dim=0).detach().cpu()\n",
    "        y_true = torch.cat([x[\"y_true\"] for x in outputs], dim=0).detach().cpu()\n",
    "        \n",
    "        \n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        self.log('f1', f1, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        self.log('val_loss', val_loss, prog_bar=True)\n",
    "        \n",
    "            \n",
    "    def optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None, on_tpu=False, using_native_amp=True, using_lbfgs=False):\n",
    "                \n",
    "        optimizer.step(closure=second_order_closure)\n",
    "\n",
    "        self.scheduler.step(current_epoch + batch_nb / len(data_loader.train_dataloader()))\n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "        \n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=epochs, T_mult=1, eta_min=0, last_epoch=-1, verbose=True)\n",
    "                \n",
    "        return optimizer\n",
    "\n",
    "\n",
    "m = LabelModel.load_from_checkpoint('label_checkpoints/epoch=03-f1=0.6386.ckpt')\n",
    "\n",
    "# torch.save(m.unsup_sage.state_dict(), 'la_sage.pt')\n",
    "torch.save(m.label_predictor.state_dict(), 'la_predictor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "unable-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelModel(pl.LightningModule):\n",
    "    def __init__(self, in_channels, hidden_channels, **kwargs):\n",
    "        super(LabelModel, self).__init__()\n",
    "        \n",
    "        self.unsup_sage = = SAGE( \n",
    "            in_channels=128, \n",
    "            hidden_channels=128, \n",
    "            num_layers=2, \n",
    "            leaf_len=leaf_len)\n",
    "        \n",
    "        self.label_predictor = LabelPredictor()\n",
    "        \n",
    "    def forward(self, x, adjs):\n",
    "        \n",
    "        x = self.unsup_sage(x, adjs)        \n",
    "        x = self.label_predictor(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, rev, adjs = batch\n",
    "        \n",
    "        y_pred = self.forward(x, adjs).flatten()\n",
    "\n",
    "        y_true = (y_true == y.roll(1,0)).long().flatten()\n",
    "\n",
    "        loss = F.binary_cross_entropy(y_pred, y_true)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, rev, adjs = batch\n",
    "        \n",
    "        threshold = 0.5\n",
    "        \n",
    "        y_pred = self.forward(x, adjs)\n",
    "        y_pred[y_pred >= threshold] = 1\n",
    "        y_pred[y_pred < threshold] = 0\n",
    "                \n",
    "        y_true = (y_true == y.roll(1,0)).long()\n",
    "                \n",
    "        return {'y_pred':y_pred.flatten(), 'y_true': y.flatten()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \n",
    "        y_pred = torch.cat([x[\"y_pred\"] for x in outputs], dim=0).detach().cpu()\n",
    "        y_true = torch.cat([x[\"y_true\"] for x in outputs], dim=0).detach().cpu()\n",
    "        \n",
    "        \n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        \n",
    "        self.log('f1', f1, prog_bar=True)\n",
    "        \n",
    "            \n",
    "    def optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None, on_tpu=False, using_native_amp=True, using_lbfgs=False):\n",
    "                \n",
    "        optimizer.step(closure=second_order_closure)\n",
    "\n",
    "        self.scheduler.step(current_epoch + batch_nb / len(data_loader.train_dataloader()))\n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        \n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100, T_mult=1, eta_min=0, last_epoch=-1, verbose=True)\n",
    "                \n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StackData(train_data, unlab_data, valid_data):\n",
    "    '''\n",
    "    stack pyG dataset.\n",
    "    because the valid/test data should include train/unlab edges\n",
    "    '''\n",
    "    stack = Data()\n",
    "    x, y, edge_index, edge_label, rev = [],[],[],[],[]\n",
    "    \n",
    "    # feature\n",
    "    x.append(train_data.x)\n",
    "    x.append(unlab_data.x)\n",
    "    x.append(valid_data.x)\n",
    "    x.append(test_data.x)\n",
    "    x = torch.cat(x,dim=0)\n",
    "    stack.x = x\n",
    "    \n",
    "    # target\n",
    "    y.append(train_data.y)\n",
    "    y.append(unlab_data.y)\n",
    "    y.append(valid_data.y)\n",
    "    y.append(test_data.y)\n",
    "    y = torch.cat(y,dim=-1)\n",
    "    stack.y = y\n",
    "    \n",
    "    # revenue\n",
    "    rev.append(train_data.rev)\n",
    "    rev.append(unlab_data.rev)\n",
    "    rev.append(valid_data.rev)\n",
    "    rev.append(test_data.rev)\n",
    "    rev = torch.cat(rev,dim=-1)\n",
    "    stack.rev = rev\n",
    "    \n",
    "    # edge index\n",
    "    stack.train_edge = torch.cat((train_data.edge_index, unlab_data.edge_index), dim=1)\n",
    "    stack.valid_edge = torch.cat((stack.train_edge,valid_data.edge_index ), dim=1)\n",
    "    stack.test_edge = torch.cat((stack.valid_edge,test_data.edge_index ), dim=1)\n",
    "    \n",
    "    # transaction index\n",
    "    stack.train_idx = train_data.node_idx\n",
    "    stack.valid_idx = valid_data.node_idx\n",
    "    stack.test_idx = test_data.node_idx\n",
    "    \n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "solid-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupSageNeighborSampler(NeighborSampler):\n",
    "    \n",
    "    def __init__(self, x, y, sage, *args, **kwargs):\n",
    "        super(UnsupSageNeighborSampler, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.sage = sage\n",
    "    \n",
    "    def sample(self, batch):\n",
    "\n",
    "        batch_size, n_id, org_adjs = super(UnsupSageNeighborSampler, self).sample(batch)\n",
    "        \n",
    "        _, unsup_n_id, adjs = super(UnsupSageNeighborSampler, self).sample(n_id)\n",
    "        with torch.no_grad():\n",
    "            unsup_emb = self.sage(self.x[unsup_n_id], adjs)\n",
    "        \n",
    "        x = self.x[n_id]\n",
    "        x_unsup = unsup_emb.detach()\n",
    "        y = self.y[n_id[:batch_size]]\n",
    "        \n",
    "        return x, x_unsup, y, org_adjs\n",
    "\n",
    "class EmbedData(LightningDataModule):\n",
    "    def __init__(self, sage, data, sizes, batch_size = 128):\n",
    "        super(EmbedData,self).__init__()\n",
    "        \n",
    "        self.sage = sage\n",
    "        self.data = data\n",
    "        self.sizes = sizes\n",
    "        self.valid_sizes = sizes\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return UnsupSageNeighborSampler(\n",
    "                               self.data.x,\n",
    "                               self.data.y,\n",
    "                               self.sage,\n",
    "                               self.data.train_edge, \n",
    "                               node_idx=self.data.train_idx,\n",
    "                               sizes=self.sizes, \n",
    "                               return_e_id=True,\n",
    "                               batch_size=self.batch_size,\n",
    "                               shuffle=True,\n",
    "                               drop_last=True,\n",
    "                               num_workers=16)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return UnsupSageNeighborSampler(\n",
    "                               self.data.x,\n",
    "                               self.data.y,\n",
    "                               self.sage,\n",
    "                               self.data.valid_edge, \n",
    "                               node_idx=self.data.valid_idx,\n",
    "                               sizes=self.sizes, \n",
    "                               return_e_id=True,\n",
    "                               batch_size=self.batch_size,\n",
    "                               shuffle=False,\n",
    "                               drop_last=True,\n",
    "                               num_workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "closing-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sage = SAGE( \n",
    "    in_channels=128, \n",
    "    hidden_channels=128, \n",
    "    num_layers=2, \n",
    "    leaf_len=leaf_len)\n",
    "\n",
    "sizes = [64, 32]\n",
    "batch_size = 1024\n",
    "\n",
    "stacked_data = StackData(train_lab_data,train_unlab_data,valid_data, test_data)\n",
    "data_loader = EmbedData(sage, stacked_data, sizes, batch_size)\n",
    "\n",
    "# ns = UnsupSageNeighborSampler(train_lab_data.x, train_lab_data.y, sage, train_lab_data.edge_index, node_idx=train_lab_data.node_idx,\n",
    "#                                sizes=[-1,-1], return_e_id=True,\n",
    "#                                batch_size=1,\n",
    "#                                shuffle=True,\n",
    "#                                drop_last=True,\n",
    "# #                                transform=train_batch,\n",
    "#                                num_workers=16)\n",
    "\n",
    "# x, x_unsup, y, adjs = ns.sample([0])\n",
    "# x.shape, x_unsup.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "handed-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter \n",
    "\n",
    "class LAConv(SAGEConv):\n",
    "    def __init__(self, label_predictor, in_channels, out_channels, **kwargs):\n",
    "        super(LAConv, self).__init__(in_channels, out_channels, aggr='add', **kwargs)\n",
    "        \n",
    "        self.label_predictor = label_predictor\n",
    "        \n",
    "        # freeze label predictor\n",
    "        for p in self.label_predictor.parameters():\n",
    "            p.requires_grad = False\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        if isinstance(x, Tensor):\n",
    "            x: OptPairTensor = (x, x)\n",
    "\n",
    "        # propagate_type: (x: OptPairTensor)\n",
    "        out = self.propagate(edge_index, x=x)\n",
    "        \n",
    "        # split to x, and unsupervised embeddings\n",
    "        out_unsup = out[:,self.in_channels:]\n",
    "        out = self.lin_l(out[:,:self.in_channels])\n",
    "\n",
    "        x_r = x[1][:,:self.in_channels]\n",
    "\n",
    "        out += self.lin_r(x_r)\n",
    "\n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2., dim=-1)\n",
    "\n",
    "        return torch.cat([out, out_unsup], dim=-1)\n",
    "    \n",
    "    def message(self, x_j, x_i, index):\n",
    "\n",
    "        '''\n",
    "        i - central node that aggregates \n",
    "        x_j has shape [E, out_channels]\n",
    "        index - indicies of the center nodes for each element in x_j\n",
    "        '''\n",
    "\n",
    "        # predicting similarity between center node and each of its neighbor \n",
    "        \n",
    "        x_unsup_j = x_j[:,self.in_channels:]\n",
    "        x_j = x_j[:,:self.in_channels]\n",
    "        \n",
    "        x_unsup_i = x_i[:,self.in_channels:]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            A_j = self.label_predictor.edge_forward(x_unsup_i, x_unsup_j)\n",
    "                \n",
    "        # sum all weights belonging to the same center node\n",
    "        A_sum_scattered = scatter(A_j, index, dim=0, reduce=\"sum\") \n",
    "        # unscattering sums\n",
    "        A_sum = A_sum_scattered[index]\n",
    "        # normalizing weights\n",
    "        A_j = A_j / A_sum\n",
    "        \n",
    "        x_j = A_j * x_j\n",
    "        x_j = torch.cat([x_j, x_unsup_j], dim=-1)\n",
    "        \n",
    "        return x_j\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ignored-bumper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 128])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graph sage with label aware aggregation \n",
    "\n",
    "class LA_SAGE(nn.Module):\n",
    "    def __init__(self, unsup_channels, in_channels, hidden_channels, num_layers, leaf_len):\n",
    "        super(LA_SAGE, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "        self.unsup_channels = unsup_channels\n",
    "        \n",
    "        self.label_predictor = LabelPredictor(unsup_channels)\n",
    "        \n",
    "        self.emb = nn.Embedding(leaf_len, in_channels, padding_idx=0)\n",
    "        self.ln = nn.LayerNorm(in_channels)\n",
    "            \n",
    "        for i in range(num_layers):\n",
    "            in_channels = in_channels if i == 0 else hidden_channels\n",
    "            self.convs.append(LAConv(self.label_predictor, in_channels, hidden_channels))\n",
    "        \n",
    "    def forward(self, x, x_unsup, adjs):\n",
    "        \n",
    "        x = self.emb(x)\n",
    "\n",
    "        x = torch.sum(x,dim=1) # summation over the leaves\n",
    "        x = F.relu(self.ln(x))\n",
    "        \n",
    "        x = torch.cat([x, x_unsup], dim=-1) # cat learned features with fixed unsup embeddings\n",
    "\n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "\n",
    "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
    "\n",
    "            x = self.convs[i]((x, x_target), edge_index)\n",
    "            \n",
    "            x_unsup = x[:,-self.unsup_channels:]\n",
    "            x = x[:,:-self.unsup_channels]\n",
    "            \n",
    "\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "                \n",
    "            x = torch.cat([x, x_unsup], dim=-1)\n",
    "                \n",
    "        return x[:,:-self.unsup_channels]\n",
    "\n",
    "# testing\n",
    "leaf_len = 1550\n",
    "sizes = [2,1]\n",
    "batch_size = 1\n",
    "\n",
    "la = LA_SAGE(\n",
    "    unsup_channels=128,\n",
    "    in_channels=128, \n",
    "    hidden_channels=128, \n",
    "    num_layers=2, \n",
    "    leaf_len=leaf_len)\n",
    "\n",
    "# x, y, rev, adjs = next(iter(sub_data_module.train_dataloader()))\n",
    "\n",
    "x, x_unsup, y, adjs = next(iter(data_loader.train_dataloader()))\n",
    "la(x, x_unsup, adjs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LA_SAGE_Model(pl.LightningModule):\n",
    "    def __init__(self, X, Y, **kwargs):\n",
    "        super(LA_SAGE_Model, self).__init__()\n",
    "        \n",
    "        self.sage = LA_SAGE(**kwargs)\n",
    "\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, adjs):\n",
    "        \n",
    "        return self.sage(x, adjs)\n",
    "        \n",
    "    \n",
    "    def full_forward(self, x, adjs):\n",
    "\n",
    "        return self.sage.full_forward(x, adjs)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, rev, adjs = batch\n",
    "        \n",
    "        out = self.forward(x, adjs)\n",
    "        \n",
    "        out, pos_out, neg_out = out.split(out.size(0) // 3, dim=0)\n",
    "\n",
    "        pos_loss = F.logsigmoid((out * pos_out).sum(-1)).mean()\n",
    "        neg_loss = F.logsigmoid(-(out * neg_out).sum(-1)).mean()\n",
    "        loss = -pos_loss - neg_loss\n",
    "             \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, rev, adjs = batch\n",
    "        \n",
    "        features = self.forward(x, adjs)\n",
    "                \n",
    "        return {'features':features, 'y': y.flatten()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \n",
    "        valid_X = torch.cat([x[\"features\"] for x in outputs], dim=0)\n",
    "        valid_y = torch.cat([x[\"y\"] for x in outputs], dim=0)\n",
    "        \n",
    "        print(self.y.shape)\n",
    "        \n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(self.X, self.y)\n",
    "        \n",
    "        score = clf.score(valid_X, valid_y)\n",
    "        \n",
    "        self.log('val_acc', score, prog_bar=True)\n",
    "            \n",
    "        self.X = None\n",
    "        self.y = None\n",
    "            \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "soviet-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using environment variable NODE_RANK for node rank (0).\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name | Type    | Params\n",
      "---------------------------------\n",
      "0 | sage | LA_SAGE | 223 K \n",
      "---------------------------------\n",
      "223 K     Trainable params\n",
      "0         Non-trainable params\n",
      "223 K     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1865 [00:00<?, ?it/s] torch.Size([59938, 128]) torch.Size([59938, 128])\n",
      "torch.Size([59938, 384])\n",
      "torch.Size([26962, 128]) torch.Size([26962, 128])\n",
      "torch.Size([26962, 384])\n",
      "Epoch 0:   0%|          | 0/1865 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-2b2c46d46919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_sanity_val_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                         \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tpu\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mTPU_AVAILABLE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musing_native_amp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0musing_lbfgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         )\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \"\"\"\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m     def optimizer_zero_grad(\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, make_optimizer_step, *args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;31m# make sure to call optimizer_closure when accumulating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[0;34m(self, closure, profiler_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0maccelerator_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    711\u001b[0m                                 \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                                 \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m                             )\n\u001b[1;32m    715\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step_and_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;31m# lightning module hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_step_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'training_step'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_logged_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, model_step, args)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-3d6754796cd2>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-3d6754796cd2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adjs)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-4a1dcb3edadd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adjs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mx_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Target nodes are always placed first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-016505aa4076>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# edge_index has shape [2, E]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mmsg_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoll_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;31m# For `GNNExplainer`, we require a separate message and aggregate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-016505aa4076>\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, x_j, x_i)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mA_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlagnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mA_j\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-47171687332d>\u001b[0m in \u001b[0;36medge_forward\u001b[0;34m(self, emb_a, emb_b)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/robert37/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "leaf_len = 1549\n",
    "\n",
    "batch_size = 256\n",
    "sizes = [-1, 200]\n",
    "\n",
    "data_loader = CustomData(train_lab_data, valid_lab_data, sizes, batch_size)\n",
    "\n",
    "model = LA_SAGE_Model(\n",
    "    train_lab_data.x, \n",
    "    train_lab_data.y, \n",
    "    in_channels=128, \n",
    "    hidden_channels=64, \n",
    "    num_layers=2, \n",
    "    leaf_len=leaf_len)\n",
    "\n",
    "trainer = Trainer(num_sanity_val_steps=0)\n",
    "trainer.fit(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-skirt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robert37",
   "language": "python",
   "name": "robert37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
