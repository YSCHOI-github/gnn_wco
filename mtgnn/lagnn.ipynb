{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "finnish-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "os.path.join('../')\n",
    "\n",
    "import parser\n",
    "import dataset\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from custom_parser import get_parser\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.utils import from_networkx, to_undirected\n",
    "from torch_geometric.data import Data, DataLoader, Dataset\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "%config Completer.use_jedi = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "waiting-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.Tdata(path='../../tdata.csv')\n",
    "parser = get_parser()\n",
    "args = parser.parse_args(args=\n",
    "                         [\"--data\",\"real-t\", \n",
    "                          \"--sampling\",\"xgb\",\n",
    "                          \"--mode\",\"scratch\",\n",
    "                          \"--train_from\",\"20140101\",\n",
    "                          \"--test_from\",\"20170101\",\n",
    "                          \"--test_length\",\"365\",\n",
    "                          \"--valid_length\",\"180\",\n",
    "                          \"--initial_inspection_rate\", \"3\",\n",
    "                          \"--final_inspection_rate\", \"10\",\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "invisible-monthly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:\n",
      "Train labeled: (40475, 41), Train unlabeled: (1308679, 41), Valid labeled: (437124, 41), Valid unlabeled: (0, 13), Test: (858180, 41)\n",
      "Checking label distribution\n",
      "Training: 0.07383529661466624\n",
      "Validation: 0.07495764097746672\n",
      "Testing: 0.0957648251549135\n"
     ]
    }
   ],
   "source": [
    "# args\n",
    "seed = args.seed\n",
    "epochs = args.epoch\n",
    "dim = args.dim\n",
    "lr = args.lr\n",
    "weight_decay = args.l2\n",
    "initial_inspection_rate = args.initial_inspection_rate\n",
    "inspection_rate_option = args.inspection_plan\n",
    "mode = args.mode\n",
    "train_begin = args.train_from \n",
    "test_begin = args.test_from\n",
    "test_length = args.test_length\n",
    "valid_length = args.valid_length\n",
    "chosen_data = args.data\n",
    "numWeeks = args.numweeks\n",
    "semi_supervised = args.semi_supervised\n",
    "save = args.save\n",
    "gpu_id = args.device\n",
    "\n",
    "# Initial dataset split\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Initial dataset split\n",
    "train_start_day = datetime.date(int(train_begin[:4]), int(train_begin[4:6]), int(train_begin[6:8]))\n",
    "test_start_day = datetime.date(int(test_begin[:4]), int(test_begin[4:6]), int(test_begin[6:8]))\n",
    "test_length = timedelta(days=test_length)    \n",
    "test_end_day = test_start_day + test_length\n",
    "valid_length = timedelta(days=valid_length)\n",
    "valid_start_day = test_start_day - valid_length\n",
    "\n",
    "# data\n",
    "data.split(train_start_day, valid_start_day, test_start_day, test_end_day, valid_length, test_length, args)\n",
    "data.featureEngineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "pressing-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../graph_sage')\n",
    "from utils import *\n",
    "from pygData_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dimensional-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n"
     ]
    }
   ],
   "source": [
    "categories=[\"importer.id\",\"HS6\"]\n",
    "gdata = GraphData(data,use_xgb=True, categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "stuffed-recorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking top 1% suspicious transactions: 4371\n",
      "Precision: 0.6287, Recall: 0.0902, Revenue: 0.1119\n",
      "Checking top 2% suspicious transactions: 8742\n",
      "Precision: 0.5420, Recall: 0.1554, Revenue: 0.1860\n",
      "Checking top 5% suspicious transactions: 21857\n",
      "Precision: 0.3742, Recall: 0.2683, Revenue: 0.3006\n",
      "Checking top 10% suspicious transactions: 43712\n",
      "Precision: 0.2683, Recall: 0.3848, Revenue: 0.4311\n",
      "--------------------------------------------------\n",
      "Checking top 1% suspicious transactions: 8581\n",
      "Precision: 0.5809, Recall: 0.0665, Revenue: 0.0778\n",
      "Checking top 2% suspicious transactions: 17164\n",
      "Precision: 0.4996, Recall: 0.1143, Revenue: 0.1364\n",
      "Checking top 5% suspicious transactions: 42909\n",
      "Precision: 0.3674, Recall: 0.2102, Revenue: 0.2498\n",
      "Checking top 10% suspicious transactions: 85818\n",
      "Precision: 0.2769, Recall: 0.3168, Revenue: 0.3690\n"
     ]
    }
   ],
   "source": [
    "best_thresh, best_auc = find_best_threshold(gdata.xgb,data.dfvalidx_lab, data.valid_cls_label)\n",
    "xgb_test_pred = gdata.xgb.predict_proba(data.dfvalidx_lab)[:,-1]\n",
    "overall_f1,auc,pr, re, f, rev = metrics(xgb_test_pred, data.valid_cls_label,data.valid_reg_label,best_thresh)\n",
    "print(\"-\"*50)\n",
    "xgb_test_pred = gdata.xgb.predict_proba(data.dftestx)[:,-1]\n",
    "overall_f1,auc,pr, re, f, rev = metrics(xgb_test_pred, data.test_cls_label,data.test_reg_label,best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "racial-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = \"train_lab\"\n",
    "trainLab_data = gdata.get_data(stage)\n",
    "train_nodeidx = torch.tensor(gdata.get_AttNode(stage))\n",
    "trainLab_data.node_idx = train_nodeidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "stuck-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = \"train_unlab\"\n",
    "unlab_data = gdata.get_data(stage)\n",
    "unlab_nodeidx = torch.tensor(gdata.get_AttNode(stage))\n",
    "unlab_data.node_idx = unlab_nodeidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "absent-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = \"valid\"\n",
    "valid_data = gdata.get_data(stage)\n",
    "valid_nodeidx = torch.tensor(gdata.get_AttNode(stage))\n",
    "valid_data.node_idx = valid_nodeidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "integral-letters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[80950], edge_index=[2, 161900], edge_label=[161900], node_idx=[40475], rev=[52368], x=[52368, 100], y=[52368])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-fighter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "capital-phone",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broken-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelPredictor(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(LabelPredictor, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(in_channels * 3, 1)\n",
    "\n",
    "    def forward(self, emb_a, emb_b): \n",
    "        \n",
    "        emb_abs = torch.abs(emb_a - emb_b)\n",
    "        emb_sum = emb_a + emb_b\n",
    "        emb_mult = emb_a * emb_b\n",
    "        \n",
    "        x = torch.cat([emb_abs, emb_sum, emb_mult], dim=-1)\n",
    "\n",
    "        x = self.linear(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GraphSage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
