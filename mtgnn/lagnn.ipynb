{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "finnish-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import List, NamedTuple, Optional\n",
    "import scipy.sparse as sp\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import parser\n",
    "import dataset\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from custom_parser import get_parser\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torch_geometric.utils import from_networkx, to_undirected\n",
    "from torch_geometric.data import Data, DataLoader, Dataset, NeighborSampler\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "from torch_cluster import random_walk\n",
    "\n",
    "from torch import Tensor\n",
    "# from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "%config Completer.use_jedi = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pointed-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "waiting-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = dataset.Tdata(path='../../tdata.csv')\n",
    "# parser = get_parser()\n",
    "# args = parser.parse_args(args=\n",
    "#                          [\"--data\",\"real-t\", \n",
    "#                           \"--sampling\",\"xgb\",\n",
    "#                           \"--mode\",\"scratch\",\n",
    "#                           \"--train_from\",\"20140101\",\n",
    "#                           \"--test_from\",\"20170101\",\n",
    "#                           \"--test_length\",\"365\",\n",
    "#                           \"--valid_length\",\"180\",\n",
    "#                           \"--initial_inspection_rate\", \"3\",\n",
    "#                           \"--final_inspection_rate\", \"10\",\n",
    "#                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "invisible-monthly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:\n",
      "Train labeled: (40475, 41), Train unlabeled: (1308679, 41), Valid labeled: (437124, 41), Valid unlabeled: (0, 13), Test: (858180, 41)\n",
      "Checking label distribution\n",
      "Training: 0.07383529661466624\n",
      "Validation: 0.07495764097746672\n",
      "Testing: 0.0957648251549135\n"
     ]
    }
   ],
   "source": [
    "# # args\n",
    "# seed = args.seed\n",
    "# epochs = args.epoch\n",
    "# dim = args.dim\n",
    "# lr = args.lr\n",
    "# weight_decay = args.l2\n",
    "# initial_inspection_rate = args.initial_inspection_rate\n",
    "# inspection_rate_option = args.inspection_plan\n",
    "# mode = args.mode\n",
    "# train_begin = args.train_from \n",
    "# test_begin = args.test_from\n",
    "# test_length = args.test_length\n",
    "# valid_length = args.valid_length\n",
    "# chosen_data = args.data\n",
    "# numWeeks = args.numweeks\n",
    "# semi_supervised = args.semi_supervised\n",
    "# save = args.save\n",
    "# gpu_id = args.device\n",
    "\n",
    "# # Initial dataset split\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "\n",
    "# # Initial dataset split\n",
    "# train_start_day = datetime.date(int(train_begin[:4]), int(train_begin[4:6]), int(train_begin[6:8]))\n",
    "# test_start_day = datetime.date(int(test_begin[:4]), int(test_begin[4:6]), int(test_begin[6:8]))\n",
    "# test_length = timedelta(days=test_length)    \n",
    "# test_end_day = test_start_day + test_length\n",
    "# valid_length = timedelta(days=valid_length)\n",
    "# valid_start_day = test_start_day - valid_length\n",
    "\n",
    "# # data\n",
    "# data.split(train_start_day, valid_start_day, test_start_day, test_end_day, valid_length, test_length, args)\n",
    "# data.featureEngineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pressing-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('../graph_sage')\n",
    "# from utils import *\n",
    "# from pygData_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dimensional-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n"
     ]
    }
   ],
   "source": [
    "# categories=[\"importer.id\",\"HS6\"]\n",
    "# gdata = GraphData(data,use_xgb=True, categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stuffed-recorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking top 1% suspicious transactions: 4371\n",
      "Precision: 0.6287, Recall: 0.0902, Revenue: 0.1119\n",
      "Checking top 2% suspicious transactions: 8742\n",
      "Precision: 0.5420, Recall: 0.1554, Revenue: 0.1860\n",
      "Checking top 5% suspicious transactions: 21857\n",
      "Precision: 0.3742, Recall: 0.2683, Revenue: 0.3006\n",
      "Checking top 10% suspicious transactions: 43712\n",
      "Precision: 0.2683, Recall: 0.3848, Revenue: 0.4311\n",
      "--------------------------------------------------\n",
      "Checking top 1% suspicious transactions: 8581\n",
      "Precision: 0.5809, Recall: 0.0665, Revenue: 0.0778\n",
      "Checking top 2% suspicious transactions: 17164\n",
      "Precision: 0.4996, Recall: 0.1143, Revenue: 0.1364\n",
      "Checking top 5% suspicious transactions: 42909\n",
      "Precision: 0.3674, Recall: 0.2102, Revenue: 0.2498\n",
      "Checking top 10% suspicious transactions: 85818\n",
      "Precision: 0.2769, Recall: 0.3168, Revenue: 0.3690\n"
     ]
    }
   ],
   "source": [
    "# best_thresh, best_auc = find_best_threshold(gdata.xgb,data.dfvalidx_lab, data.valid_cls_label)\n",
    "# xgb_test_pred = gdata.xgb.predict_proba(data.dfvalidx_lab)[:,-1]\n",
    "# overall_f1,auc,pr, re, f, rev = metrics(xgb_test_pred, data.valid_cls_label,data.valid_reg_label,best_thresh)\n",
    "# print(\"-\"*50)\n",
    "# xgb_test_pred = gdata.xgb.predict_proba(data.dftestx)[:,-1]\n",
    "# overall_f1,auc,pr, re, f, rev = metrics(xgb_test_pred, data.test_cls_label,data.test_reg_label,best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "racial-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage = \"train_lab\"\n",
    "# trainLab_data = gdata.get_data(stage)\n",
    "# train_nodeidx = torch.tensor(gdata.get_AttNode(stage))\n",
    "# trainLab_data.node_idx = train_nodeidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stuck-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage = \"train_unlab\"\n",
    "# unlab_data = gdata.get_data(stage)\n",
    "# unlab_nodeidx = torch.tensor(gdata.get_AttNode(stage))\n",
    "# unlab_data.node_idx = unlab_nodeidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "absent-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage = \"valid\"\n",
    "# valid_data = gdata.get_data(stage)\n",
    "# valid_nodeidx = torch.tensor(gdata.get_AttNode(stage))\n",
    "# valid_data.node_idx = valid_nodeidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adjusted-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(valid_data, 'valid_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "integral-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainLab_data, gdata.leaf_dim\n",
    "# gdata.leaf_dim # 1549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "voluntary-pledge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[874248], edge_index=[2, 1748496], edge_label=[1748496], node_idx=[437124], rev=[467973], x=[467973, 100], y=[467973])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lab_data = torch.load('train_data.pt')\n",
    "train_lab_data\n",
    "\n",
    "valid_lab_data = torch.load('valid_data.pt')\n",
    "valid_lab_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-idaho",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "amateur-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch(NamedTuple):\n",
    "    '''\n",
    "    convert batch data for pytorch-lightning\n",
    "    '''\n",
    "    x: Tensor\n",
    "    y: Tensor\n",
    "    rev: Tensor\n",
    "    adjs_t: NamedTuple\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        return Batch(\n",
    "            x=self.x.to(*args, **kwargs),\n",
    "            y=self.y.to(*args, **kwargs),\n",
    "            rev=self.rev.to(*args, **kwargs),\n",
    "            adjs_t=[(adj_t.to(*args, **kwargs), eid.to(*args, **kwargs), size) for adj_t, eid, size in self.adjs_t],\n",
    "        )\n",
    "    \n",
    "class UnsupNeighborSampler(NeighborSampler):\n",
    "    \n",
    "    def sample(self, batch):\n",
    "        batch = torch.tensor(batch)\n",
    "        row, col, _ = self.adj_t.coo()\n",
    "\n",
    "        # For each node in `batch`, we sample a direct neighbor (as positive\n",
    "        # example) and a random node (as negative example):\n",
    "        pos_batch = random_walk(row, col, batch, walk_length=1,\n",
    "                                coalesced=False)[:, 1]\n",
    "\n",
    "        neg_batch = torch.randint(0, self.adj_t.size(1), (batch.numel(), ),\n",
    "                                  dtype=torch.long)\n",
    "\n",
    "        batch = torch.cat([batch, pos_batch, neg_batch], dim=0)\n",
    "        return super(UnsupNeighborSampler, self).sample(batch)\n",
    "    \n",
    "class CustomData(LightningDataModule):\n",
    "    def __init__(self,train_data, valid_data, sizes, batch_size):\n",
    "        super(CustomData,self).__init__()\n",
    "\n",
    "        self.train_data = train_data\n",
    "        self.valid_data = valid_data\n",
    "        \n",
    "        self.sizes = sizes\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return UnsupNeighborSampler(self.train_data.edge_index, node_idx=self.train_data.node_idx,\n",
    "                               sizes=self.sizes, return_e_id=True,\n",
    "                               batch_size=self.batch_size,\n",
    "                               shuffle=True,\n",
    "                               drop_last=True,\n",
    "                               transform=self.convert_train_batch,\n",
    "                               num_workers=16)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return NeighborSampler(self.valid_data.edge_index, \n",
    "                               node_idx=self.valid_data.node_idx,\n",
    "                               sizes=self.sizes, \n",
    "                               return_e_id=True,\n",
    "                               batch_size=self.batch_size,\n",
    "                               shuffle=False,\n",
    "                               drop_last=True,\n",
    "                               transform=self.convert_valid_batch\n",
    "                              )\n",
    "\n",
    "    def convert_train_batch(self, batch_size, n_id, adjs):\n",
    "        return Batch(\n",
    "            x=self.train_data.x[n_id],\n",
    "            y=self.train_data.y[n_id[:batch_size]],\n",
    "            rev = self.train_data.rev[n_id[:batch_size]],\n",
    "            adjs_t=adjs,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def convert_valid_batch(self, batch_size, n_id, adjs):\n",
    "        return Batch(\n",
    "            x=self.valid_data.x[n_id],\n",
    "            y=self.valid_data.y[n_id[:batch_size]],\n",
    "            rev = self.valid_data.rev[n_id[:batch_size]],\n",
    "            adjs_t=adjs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-phone",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "broken-hollywood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7006, 0.9475, 0.2457, 0.5078],\n",
      "        [0.2457, 0.0703, 0.7142, 0.6278]])\n",
      "tensor([[0.2457, 0.0703, 0.7142, 0.6278],\n",
      "        [0.7006, 0.9475, 0.2457, 0.5078]])\n",
      "tensor([[0.7006, 0.9475, 0.2457, 0.5078],\n",
      "        [0.2457, 0.0703, 0.7142, 0.6278]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LabelPredictor(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(LabelPredictor, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(in_channels * 3, 1)\n",
    "        \n",
    "    def forward(self, x): \n",
    "      \n",
    "        emb_a = x\n",
    "        emb_b = x.roll(1,0)\n",
    "        \n",
    "        print(emb_b)\n",
    "        print(emb_a)\n",
    "        emb_abs = torch.abs(emb_a - emb_b)\n",
    "        emb_sum = emb_a + emb_b\n",
    "        emb_mult = emb_a * emb_b\n",
    "        \n",
    "        x = torch.cat([emb_abs, emb_sum, emb_mult], dim=-1)\n",
    "\n",
    "        x = self.linear(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "lp = LabelPredictor(4)\n",
    "\n",
    "x = torch.rand(2,4)\n",
    "print(x)\n",
    "lp(x).shape\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "skilled-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers, leaf_len):\n",
    "        super(SAGE, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "        self.emb = nn.Embedding(leaf_len, in_channels, padding_idx=0)\n",
    "        self.bn = nn.BatchNorm1d(in_channels)\n",
    "            \n",
    "        for i in range(num_layers):\n",
    "            in_channels = in_channels if i == 0 else hidden_channels\n",
    "            self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "\n",
    "        \n",
    "    def forward(self, x, adjs):\n",
    "        \n",
    "        x = self.emb(x)\n",
    "\n",
    "        x = torch.sum(x,dim=1) # summation over the leaves\n",
    "        x = F.relu(self.bn(x))\n",
    "        \n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
    "            x = self.convs[i]((x, x_target), edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "                \n",
    "        return x\n",
    "\n",
    "#     def full_forward(self, x, edge_index):\n",
    "        \n",
    "#         x = self.emb(x)\n",
    "\n",
    "#         x = torch.sum(x,dim=1) # summation over the leaves\n",
    "#         x = F.relu(self.bn(x))\n",
    "        \n",
    "#         for i, conv in enumerate(self.convs):\n",
    "#             x = conv(x, edge_index)\n",
    "#             if i != self.num_layers - 1:\n",
    "#                 x = x.relu()\n",
    "#                 x = F.dropout(x, p=0.5, training=self.training)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "grand-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SageModel(pl.LightningModule):\n",
    "    def __init__(self, X, Y, **kwargs):\n",
    "        super(SageModel, self).__init__()\n",
    "        \n",
    "        self.sage = SAGE(**kwargs)\n",
    "\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, adjs):\n",
    "        \n",
    "        return self.sage(x, adjs)\n",
    "        \n",
    "    \n",
    "    def full_forward(self, x, adjs):\n",
    "\n",
    "        return self.sage.full_forward(x, adjs)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, rev, adjs = batch\n",
    "        \n",
    "        out = self.forward(x, adjs)\n",
    "        \n",
    "        out, pos_out, neg_out = out.split(out.size(0) // 3, dim=0)\n",
    "\n",
    "        pos_loss = F.logsigmoid((out * pos_out).sum(-1)).mean()\n",
    "        neg_loss = F.logsigmoid(-(out * neg_out).sum(-1)).mean()\n",
    "        loss = -pos_loss - neg_loss\n",
    "        \n",
    "        if not self.X is None:\n",
    "            self.X = torch.cat([self.X, out])\n",
    "            self.y = torch.cat([self.y, y.flatten()])\n",
    "        else:\n",
    "            self.X = out\n",
    "            self.y = y.flatten()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, rev, adjs = batch\n",
    "        \n",
    "        features = self.forward(x, adjs)\n",
    "                \n",
    "        return {'features':features, 'y': y.flatten()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \n",
    "        valid_X = torch.cat([x[\"features\"] for x in outputs], dim=0)\n",
    "        valid_y = torch.cat([x[\"y\"] for x in outputs], dim=0)\n",
    "        \n",
    "        print(self.y.shape)\n",
    "        \n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(self.X, self.y)\n",
    "        \n",
    "        score = clf.score(valid_X, valid_y)\n",
    "        \n",
    "        self.log('val_acc', score, prog_bar=True)\n",
    "            \n",
    "        self.X = None\n",
    "        self.y = None\n",
    "            \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fatal-envelope",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | sage | SAGE | 223 K \n",
      "------------------------------\n",
      "223 K     Trainable params\n",
      "0         Non-trainable params\n",
      "223 K     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 17/1865 [01:25<2:35:09,  5.04s/it, loss=1.95, v_num=36]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_len = 1549\n",
    "\n",
    "batch_size = 256\n",
    "sizes = [-1, 200]\n",
    "\n",
    "data_loader = CustomData(train_lab_data, valid_lab_data, sizes, batch_size)\n",
    "\n",
    "model = SageModel(\n",
    "    train_lab_data.x, \n",
    "    train_lab_data.y, \n",
    "    in_channels=128, \n",
    "    hidden_channels=64, \n",
    "    num_layers=2, \n",
    "    leaf_len=leaf_len)\n",
    "\n",
    "trainer = Trainer(num_sanity_val_steps=0)\n",
    "trainer.fit(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "attempted-johnson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-rally",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robert37",
   "language": "python",
   "name": "robert37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
